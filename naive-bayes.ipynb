{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c74bc80-89d5-4df3-aae3-f6830082ca0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Improved Naive Bayes\n",
      "W:   Accuracy: 48.45%   Precision: 53.10%   Recall: 13.03%   F1: 20.92%\n",
      "A:   Accuracy: 58.41%   Precision: 38.66%   Recall: 09.64%   F1: 15.43%\n",
      "S:   Accuracy: 96.16%   Precision: 05.00%   Recall: 01.50%   F1: 02.31%\n",
      "G:   Accuracy: 93.30%   Precision: 00.00%   Recall: 00.00%   F1: 00.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def parse(text, stop_words):\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        if word not in stop_words:\n",
    "            words.append(word)\n",
    "\n",
    "    combine_words = []\n",
    "    for i in range(len(words) - 1):\n",
    "        first = words[i]\n",
    "        second = words[i + 1]\n",
    "        combine_word = first + '_' + second\n",
    "        combine_words.append(combine_word)\n",
    "\n",
    "    return words + combine_words\n",
    "\n",
    "def k_fold(dataset, k):\n",
    "    dataset = dataset.sample(frac=1, random_state=50).reset_index(drop=True)\n",
    "    folds = []\n",
    "\n",
    "    for i in range(k):\n",
    "        starting_index = i * (len(dataset) // k)\n",
    "        if i == k - 1:\n",
    "            ending_index = len(dataset)\n",
    "        else:\n",
    "            ending_index = (i + 1) * (len(dataset) // k)\n",
    "\n",
    "        test_fold_portion = dataset[starting_index:ending_index].reset_index(drop=True)\n",
    "        train_fold_front = dataset[:starting_index]\n",
    "        train_fold_back = dataset[ending_index:]\n",
    "        train_fold_portion = pd.concat([train_fold_front, train_fold_back]).reset_index(drop=True)\n",
    "        folds.append((train_fold_portion, test_fold_portion))\n",
    "\n",
    "    return folds\n",
    "\n",
    "def improved_naive_bayes(dataset, k_folds=10):\n",
    "    labels = dataset['Class'].unique()\n",
    "    label_counts_total = {label: 0 for label in labels}\n",
    "    label_word_counts_total = {label: {} for label in labels}\n",
    "    words = set()\n",
    "    stop_words = {\n",
    "        'a', 'an', 'and', 'the', 'is', 'in', 'at', 'of', 'on', 'for', 'to', 'with', 'by', 'this', \n",
    "        'that', 'it', 'as', 'are', 'be', 'from', 'or', 'was', 'were', 'but', 'not', 'have', \n",
    "        'has', 'had'\n",
    "    }\n",
    "\n",
    "    # Word frequencies per fold\n",
    "    folds = k_fold(dataset, k_folds)  \n",
    "    for fold in folds:\n",
    "        train_fold = fold[0]\n",
    "        for i in range(len(train_fold)):\n",
    "            label = train_fold['Class'].iloc[i]\n",
    "            tokens = parse(train_fold['Description'].iloc[i], stop_words) # removes stop words and bigrams\n",
    "            label_counts_total[label] += 1\n",
    "\n",
    "            for token in tokens:\n",
    "                words.add(token)\n",
    "                if token not in label_word_counts_total[label]:\n",
    "                    label_word_counts_total[label][token] = 0\n",
    "                else:\n",
    "                    label_word_counts_total[label][token] += 1\n",
    "\n",
    "    words = list(words)\n",
    "\n",
    "    # Prior probabilities for each class\n",
    "    prior_probability = {}\n",
    "    for label in labels:\n",
    "        prior_probability[label] = np.log(label_counts_total[label] / sum(label_counts_total.values()))\n",
    "\n",
    "    # Conditional probabilities for each word given a class\n",
    "    word_probabilities = {label: {} for label in labels}\n",
    "    for label in labels:\n",
    "        total_words = sum(label_word_counts_total[label].values())\n",
    "        for word in words:\n",
    "            count = label_word_counts_total[label].get(word, 0)\n",
    "            word_probabilities[label][word] = np.log((count + 1) / (total_words + len(words)))\n",
    "\n",
    "    return labels, label_word_counts_total, words, prior_probability, word_probabilities\n",
    "\n",
    "def predict(test, labels, label_word_counts, words, prior_probability, word_probabilities, filename='result.csv'):\n",
    "    predictions = []\n",
    "    words = set(words)\n",
    "    words_size = len(words)\n",
    "\n",
    "    # Predict label for each example\n",
    "    for i in range(len(test)):\n",
    "        id = test['Id'].iloc[i]\n",
    "        tokens = test['Description'].iloc[i].split()\n",
    "        probability = {}\n",
    "\n",
    "        # Log-probability of each label given the tokens\n",
    "        for label in labels:\n",
    "            score = prior_probability[label]\n",
    "            total_words = sum(label_word_counts[label].values())\n",
    "            for word in tokens:\n",
    "                if word in words:\n",
    "                    score += word_probabilities[label].get(word, np.log(1 / (total_words + words_size)))\n",
    "            probability[label] = score\n",
    "\n",
    "        # Label with highest log probability\n",
    "        highest_score = 0\n",
    "        predicted_label = 0\n",
    "\n",
    "        for label in probability:\n",
    "            score = probability[label]\n",
    "            if highest_score == 0 or score > highest_score:\n",
    "                highest_score = score\n",
    "                predicted_label = label\n",
    "\n",
    "        predictions.append((id, predicted_label))\n",
    "\n",
    "    # Save to .csv and return prediction result\n",
    "    pd.DataFrame(predictions, columns=['Id', 'Class']).to_csv(filename, index=False)\n",
    "    return predictions\n",
    "\n",
    "def confusion_matrix(dataset, labels, predictions):\n",
    "    TP = {label: 0 for label in labels}\n",
    "    FP = {label: 0 for label in labels}\n",
    "    FN = {label: 0 for label in labels}\n",
    "    TN = {label: 0 for label in labels}\n",
    "\n",
    "    # Recording predicted data to actual data\n",
    "    prediction_dictionary = dict(predictions)\n",
    "    for i in range(len(dataset)):\n",
    "        Id = dataset['Id'].iloc[i]\n",
    "        predict_label = prediction_dictionary.get(Id)\n",
    "        actual_label = dataset['Class'].iloc[i]\n",
    "\n",
    "        for label in labels:\n",
    "            TP[label] += (predict_label == label and actual_label == label)\n",
    "            FP[label] += (predict_label == label and actual_label != label)\n",
    "            FN[label] += (predict_label != label and actual_label == label)\n",
    "            TN[label] += (predict_label != label and actual_label != label)\n",
    "\n",
    "    # Output evaluation result\n",
    "    for label in labels:\n",
    "        tp = TP[label]\n",
    "        fp = FP[label]\n",
    "        fn = FN[label]\n",
    "        tn = TN[label]\n",
    "\n",
    "        accuracy = (tp + tn) / (tp + fp + fn + tn) \n",
    "        precision = tp / (tp + fp) \n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        print(f'{label}:   Accuracy: {accuracy * 100:05.2f}%   Precision: {precision * 100:05.2f}%   Recall: {recall * 100:05.2f}%   F1: {f1 * 100:05.2f}%')\n",
    "\n",
    "# Loading data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Train and test both model\n",
    "print('Model Improved Naive Bayes')\n",
    "labels, label_word_counts, words, prior_probability, word_probabilities = improved_naive_bayes(train)\n",
    "predictions = predict(test, labels, label_word_counts, words, prior_probability, word_probabilities)\n",
    "confusion_matrix(train, labels, predictions) # Evaluate model performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
